{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim.lr_scheduler as lr_sch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "batch_size=100\n",
    "valid_batch_size=1000\n",
    "test_batch_size=10000\n",
    "\n",
    "download_root = './data'\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(root = download_root, train=True,\n",
    "                                      transform=transform, download=True)\n",
    "trainset, validset = torch.utils.data.random_split(dataset, [45000,5000])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(validset, batch_size=valid_batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=download_root, train=False,\n",
    "                                       download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=test_batch_size,\n",
    "                                         shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current cuda device  0\n",
      "TITAN Xp\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "GPU_NUM = 0 # 원하는 GPU 번호 입력\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device) # change allocation of current GPU\n",
    "print ('Current cuda device ', torch.cuda.current_device()) # check\n",
    "\n",
    "# Additional Infos\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(GPU_NUM))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(GPU_NUM)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(GPU_NUM)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # 이미지를 보여주기 위한 함수\n",
    "\n",
    "# def imshow(img):\n",
    "#     img = img / 2 + 0.5     # unnormalize\n",
    "#     npimg = img.numpy()\n",
    "#     plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# # 학습용 이미지를 무작위로 가져오기\n",
    "# dataiter = iter(trainloader)\n",
    "# images, labels = dataiter.next()\n",
    "\n",
    "# # 이미지 보여주기\n",
    "# imshow(torchvision.utils.make_grid(images))\n",
    "# # 정답(label) 출력\n",
    "# print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (features_A): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (8): ReLU()\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (12): ReLU()\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (features_C): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (8): ReLU()\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (12): ReLU()\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classifier_A): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=10, bias=True)\n",
      "  )\n",
      "  (classifier_C): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "'''Defining NN'''\n",
    "from torch.nn.init import xavier_uniform_,uniform_\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    '''fc1_A shows d_p array that accumulates gradient updates\n",
    "       fc1_c shows actual weight parameter array\n",
    "       \n",
    "       At the very first time, parameters of array A for all fc1,2,3\n",
    "       have to be initialized to zero\n",
    "       \n",
    "       And then updtaed gradients will only be accumulated on A\n",
    "       while leaving C array as it is until k==ns\n",
    "       \n",
    "       x: inputs\n",
    "       '''\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Net, self).__init__()\n",
    "        self.features_A = nn.Sequential(\n",
    "            nn.Conv2d(3,64,kernel_size=3, stride=1, padding=1,bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "        \n",
    "            nn.Conv2d(64,64,kernel_size=3,stride=1,padding=1,bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            \n",
    "            nn.Conv2d(64,128,kernel_size=3, stride=1,padding=1,bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "        \n",
    "            nn.Conv2d(128,128,kernel_size=3,stride=1,padding=1,bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.BatchNorm2d(128)\n",
    "            )\n",
    "#         for i in range(len(self.features_A)):\n",
    "#             if type(self.features_A[i])==nn.Conv2d:\n",
    "#                 torch.nn.init.zeros_(self.features_A[i].weight)\n",
    "#                 if self.features_A[i].bias is not None:\n",
    "#                     torch.nn.init.zeros_(self.features_A[i].bias)\n",
    "                    \n",
    "#         classname = self.features_A.__class__.__name__\n",
    "#         if classname.find('Conv') != -1:\n",
    "#             torch.nn.init.zeros_(self.features_A.weight)\n",
    "            \n",
    "        self.features_C = nn.Sequential(\n",
    "            nn.Conv2d(3,64,kernel_size=3, stride=1, padding=1,bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "        \n",
    "            nn.Conv2d(64,64,kernel_size=3,stride=1,padding=1,bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            \n",
    "            nn.Conv2d(64,128,kernel_size=3, stride=1,padding=1,bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "        \n",
    "            nn.Conv2d(128,128,kernel_size=3,stride=1,padding=1,bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.BatchNorm2d(128)\n",
    "            )\n",
    "        self.classifier_A = nn.Sequential(\n",
    "            nn.Linear(128*4*4, num_classes))\n",
    "        self.classifier_A[0].weight.data.fill_(0)\n",
    "#         if isinstance(self.classifier_A, nn.Linear):\n",
    "#             nn.init.zeros_(self.classifier_A.weight)\n",
    "\n",
    "#         for i in range(len(self.classifier_A)):\n",
    "#             if type(self.classifier_A[i])==nn.Linear:\n",
    "#                 torch.nn.init.zeros_(self.classifier_A[i].weight)\n",
    "#                 if self.classifier_A[i].bias is not None:\n",
    "#                     torch.nn.init.zeros_(self.classifier_A[i].bias)\n",
    "        self.classifier_C = nn.Sequential(\n",
    "            nn.Linear(128*4*4, num_classes))\n",
    "#         import pdb; pdb.set_trace()\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        gamma=1\n",
    "        x = gamma*self.features_A(x)+self.features_C(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = gamma*self.classifier_A(x) + self.classifier_C(x)\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "    \n",
    "# def weights_init(m):\n",
    "#         if isinstance(m, nn.Conv2d):\n",
    "#             nn.init.zeros_(m.weight)\n",
    "#             if m.bias is not None:\n",
    "#                 nn.init.zeros_(m.bias)   \n",
    "        \n",
    "print(model)\n",
    "# model.to(device)\n",
    "# model.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (features_A): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (8): ReLU()\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (12): ReLU()\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (features_C): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (8): ReLU()\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (12): ReLU()\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier_A): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=10, bias=True)\n",
       "  )\n",
       "  (classifier_C): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if torch.cuda.device_count()>1:\n",
    "#     print(\"Let's use\", torch.cuda.device_count(), \"GPUS!\")\n",
    "#     model = nn.DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Net'>\n"
     ]
    }
   ],
   "source": [
    "if type(model.children())==nn.Linear:\n",
    "    model.children().weight.fill_(0.0)\n",
    "params = list(model.children())\n",
    "# print(params)\n",
    "print(type(Net()))\n",
    "# print(type(model.children()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 3, 3])\n",
      "torch.Size([64, 3, 3, 3])\n",
      "0th parameter:Parameter containing:\n",
      "tensor([[[[ 0.1341,  0.0823, -0.1250],\n",
      "          [-0.1837,  0.0800,  0.1381],\n",
      "          [-0.0719,  0.0988, -0.1503]],\n",
      "\n",
      "         [[ 0.0223,  0.0232, -0.1303],\n",
      "          [-0.1196,  0.1263,  0.0268],\n",
      "          [ 0.1151,  0.1589, -0.0684]],\n",
      "\n",
      "         [[ 0.1017, -0.1225,  0.1417],\n",
      "          [ 0.0622,  0.0065, -0.0376],\n",
      "          [ 0.1862,  0.1509,  0.1833]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0464,  0.1040, -0.1041],\n",
      "          [-0.1658, -0.0342,  0.0293],\n",
      "          [ 0.0646,  0.1536, -0.0286]],\n",
      "\n",
      "         [[-0.1057, -0.1644,  0.0537],\n",
      "          [ 0.1793, -0.0094,  0.1742],\n",
      "          [ 0.1126, -0.1913, -0.0216]],\n",
      "\n",
      "         [[-0.0922, -0.0092, -0.0259],\n",
      "          [ 0.0740,  0.1916,  0.1500],\n",
      "          [ 0.1202, -0.1164,  0.0646]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1302,  0.1298, -0.0633],\n",
      "          [ 0.1641, -0.1608, -0.0030],\n",
      "          [ 0.1517,  0.0443,  0.1603]],\n",
      "\n",
      "         [[-0.1260, -0.1202,  0.0493],\n",
      "          [ 0.0650,  0.1394, -0.1427],\n",
      "          [ 0.1816, -0.0679,  0.1649]],\n",
      "\n",
      "         [[ 0.1127,  0.0574, -0.0032],\n",
      "          [ 0.0282, -0.0601,  0.1415],\n",
      "          [-0.1020, -0.1465, -0.0049]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0262, -0.1890, -0.0706],\n",
      "          [ 0.0641, -0.0893, -0.0600],\n",
      "          [-0.0978,  0.1707, -0.0088]],\n",
      "\n",
      "         [[-0.1612,  0.1685, -0.1403],\n",
      "          [ 0.1874,  0.0247, -0.0795],\n",
      "          [-0.0947, -0.0512, -0.1350]],\n",
      "\n",
      "         [[ 0.1267, -0.1422,  0.1661],\n",
      "          [-0.0305,  0.0124,  0.1618],\n",
      "          [-0.1534, -0.0277, -0.0673]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1046, -0.0842, -0.1697],\n",
      "          [ 0.0163, -0.0859, -0.1088],\n",
      "          [-0.0611, -0.1498,  0.1845]],\n",
      "\n",
      "         [[ 0.0941,  0.1912,  0.1655],\n",
      "          [-0.1914, -0.1370,  0.0046],\n",
      "          [ 0.0399, -0.1275, -0.1681]],\n",
      "\n",
      "         [[ 0.0977, -0.1495,  0.0875],\n",
      "          [-0.0655, -0.1725,  0.0472],\n",
      "          [-0.1319,  0.1807, -0.1763]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1777, -0.0583, -0.0242],\n",
      "          [-0.1188,  0.1577, -0.1622],\n",
      "          [ 0.1766,  0.1837,  0.1055]],\n",
      "\n",
      "         [[ 0.1747, -0.0948, -0.1439],\n",
      "          [-0.0856,  0.0393,  0.0315],\n",
      "          [-0.0408,  0.0186, -0.1503]],\n",
      "\n",
      "         [[-0.0601, -0.0091,  0.0695],\n",
      "          [ 0.0473,  0.1780, -0.0140],\n",
      "          [-0.0694, -0.0223, -0.0869]]]], device='cuda:0', requires_grad=True)\n",
      "torch.Size([64, 3, 3, 3])\n",
      "\n",
      "\n",
      "1th parameter:Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "torch.Size([64])\n",
      "\n",
      "\n",
      "2th parameter:Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "torch.Size([64])\n",
      "\n",
      "\n",
      "3th parameter:Parameter containing:\n",
      "tensor([[[[ 0.0216, -0.0117,  0.0135],\n",
      "          [ 0.0023,  0.0207, -0.0327],\n",
      "          [ 0.0086,  0.0200,  0.0108]],\n",
      "\n",
      "         [[ 0.0037, -0.0105,  0.0165],\n",
      "          [ 0.0352, -0.0403,  0.0230],\n",
      "          [ 0.0247,  0.0185, -0.0394]],\n",
      "\n",
      "         [[-0.0105, -0.0414, -0.0237],\n",
      "          [-0.0092, -0.0104,  0.0131],\n",
      "          [-0.0008, -0.0062, -0.0109]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0042, -0.0182, -0.0344],\n",
      "          [-0.0011,  0.0218, -0.0081],\n",
      "          [-0.0196, -0.0393, -0.0259]],\n",
      "\n",
      "         [[-0.0111,  0.0077, -0.0091],\n",
      "          [-0.0233,  0.0071,  0.0258],\n",
      "          [ 0.0372,  0.0358,  0.0192]],\n",
      "\n",
      "         [[-0.0037,  0.0338,  0.0187],\n",
      "          [ 0.0181, -0.0083, -0.0364],\n",
      "          [-0.0229,  0.0331, -0.0312]]],\n",
      "\n",
      "\n",
      "        [[[-0.0146, -0.0208,  0.0052],\n",
      "          [-0.0245, -0.0286,  0.0146],\n",
      "          [ 0.0006,  0.0118,  0.0070]],\n",
      "\n",
      "         [[ 0.0033, -0.0213,  0.0051],\n",
      "          [-0.0130,  0.0280, -0.0408],\n",
      "          [-0.0306,  0.0360,  0.0119]],\n",
      "\n",
      "         [[-0.0122, -0.0298,  0.0163],\n",
      "          [ 0.0378, -0.0322,  0.0002],\n",
      "          [-0.0169, -0.0119,  0.0325]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0330,  0.0232,  0.0415],\n",
      "          [ 0.0246,  0.0388, -0.0071],\n",
      "          [-0.0281, -0.0314, -0.0062]],\n",
      "\n",
      "         [[-0.0252, -0.0145,  0.0165],\n",
      "          [-0.0309,  0.0367, -0.0283],\n",
      "          [ 0.0273, -0.0192,  0.0006]],\n",
      "\n",
      "         [[ 0.0136, -0.0132, -0.0379],\n",
      "          [ 0.0130, -0.0359,  0.0389],\n",
      "          [-0.0312, -0.0205, -0.0013]]],\n",
      "\n",
      "\n",
      "        [[[-0.0140, -0.0216,  0.0112],\n",
      "          [-0.0204,  0.0041,  0.0019],\n",
      "          [-0.0368,  0.0235, -0.0303]],\n",
      "\n",
      "         [[-0.0027,  0.0229, -0.0121],\n",
      "          [ 0.0257,  0.0059, -0.0067],\n",
      "          [ 0.0405,  0.0298,  0.0372]],\n",
      "\n",
      "         [[-0.0384,  0.0129,  0.0143],\n",
      "          [-0.0020, -0.0272,  0.0072],\n",
      "          [ 0.0007, -0.0092, -0.0260]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0168,  0.0118,  0.0363],\n",
      "          [ 0.0341, -0.0082, -0.0048],\n",
      "          [ 0.0288,  0.0260,  0.0345]],\n",
      "\n",
      "         [[-0.0145,  0.0291,  0.0004],\n",
      "          [-0.0181,  0.0047,  0.0224],\n",
      "          [-0.0302,  0.0127, -0.0118]],\n",
      "\n",
      "         [[-0.0052, -0.0204, -0.0026],\n",
      "          [-0.0382,  0.0155,  0.0193],\n",
      "          [-0.0188, -0.0335, -0.0229]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0045, -0.0300, -0.0030],\n",
      "          [-0.0363,  0.0048,  0.0110],\n",
      "          [-0.0224, -0.0162,  0.0182]],\n",
      "\n",
      "         [[ 0.0282, -0.0371, -0.0409],\n",
      "          [-0.0015,  0.0175, -0.0298],\n",
      "          [-0.0192,  0.0088,  0.0173]],\n",
      "\n",
      "         [[ 0.0201,  0.0051, -0.0087],\n",
      "          [-0.0026,  0.0314, -0.0192],\n",
      "          [-0.0201, -0.0132, -0.0052]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0359,  0.0356, -0.0043],\n",
      "          [-0.0101,  0.0060,  0.0246],\n",
      "          [-0.0393,  0.0218,  0.0282]],\n",
      "\n",
      "         [[-0.0013, -0.0190,  0.0043],\n",
      "          [ 0.0132,  0.0174, -0.0019],\n",
      "          [-0.0321, -0.0113,  0.0094]],\n",
      "\n",
      "         [[ 0.0205, -0.0070,  0.0188],\n",
      "          [-0.0193,  0.0127,  0.0167],\n",
      "          [-0.0069, -0.0414, -0.0069]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0232, -0.0328,  0.0165],\n",
      "          [ 0.0174,  0.0197, -0.0263],\n",
      "          [-0.0108,  0.0036,  0.0320]],\n",
      "\n",
      "         [[ 0.0067,  0.0398, -0.0258],\n",
      "          [-0.0281, -0.0133, -0.0075],\n",
      "          [ 0.0385, -0.0156,  0.0244]],\n",
      "\n",
      "         [[ 0.0394,  0.0147,  0.0161],\n",
      "          [-0.0263,  0.0134, -0.0283],\n",
      "          [-0.0207, -0.0257, -0.0168]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0195, -0.0059, -0.0203],\n",
      "          [-0.0040,  0.0129, -0.0353],\n",
      "          [ 0.0298,  0.0097, -0.0092]],\n",
      "\n",
      "         [[ 0.0153,  0.0053, -0.0340],\n",
      "          [ 0.0349, -0.0155, -0.0239],\n",
      "          [-0.0235,  0.0112,  0.0402]],\n",
      "\n",
      "         [[ 0.0352,  0.0019, -0.0077],\n",
      "          [-0.0158, -0.0390,  0.0200],\n",
      "          [ 0.0118, -0.0307,  0.0009]]],\n",
      "\n",
      "\n",
      "        [[[-0.0207, -0.0075, -0.0246],\n",
      "          [ 0.0029,  0.0362, -0.0081],\n",
      "          [ 0.0229,  0.0247, -0.0390]],\n",
      "\n",
      "         [[-0.0158,  0.0360, -0.0304],\n",
      "          [ 0.0191,  0.0164, -0.0351],\n",
      "          [ 0.0383, -0.0128,  0.0070]],\n",
      "\n",
      "         [[ 0.0166, -0.0012, -0.0250],\n",
      "          [ 0.0117, -0.0234, -0.0359],\n",
      "          [-0.0145, -0.0133,  0.0188]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0133, -0.0135, -0.0267],\n",
      "          [ 0.0135, -0.0383,  0.0050],\n",
      "          [-0.0217, -0.0005, -0.0245]],\n",
      "\n",
      "         [[-0.0378, -0.0313, -0.0392],\n",
      "          [ 0.0018,  0.0375, -0.0052],\n",
      "          [-0.0325, -0.0053,  0.0116]],\n",
      "\n",
      "         [[-0.0338, -0.0139, -0.0247],\n",
      "          [ 0.0055,  0.0343,  0.0283],\n",
      "          [ 0.0143,  0.0337, -0.0210]]]], device='cuda:0', requires_grad=True)\n",
      "torch.Size([64, 64, 3, 3])\n",
      "\n",
      "\n",
      "4th parameter:Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "torch.Size([64])\n",
      "\n",
      "\n",
      "5th parameter:Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "torch.Size([64])\n",
      "\n",
      "\n",
      "6th parameter:Parameter containing:\n",
      "tensor([[[[-3.1635e-02,  2.4156e-02,  1.2063e-02],\n",
      "          [ 2.3652e-02,  1.6879e-03, -1.0980e-02],\n",
      "          [-4.1362e-02,  1.1184e-02,  1.3971e-02]],\n",
      "\n",
      "         [[ 6.1276e-03,  2.9656e-02,  3.3321e-02],\n",
      "          [ 3.9742e-02,  2.2515e-02, -1.2842e-02],\n",
      "          [ 1.6171e-02, -8.4092e-03, -1.8970e-02]],\n",
      "\n",
      "         [[ 2.0389e-02, -4.2256e-03,  1.4813e-02],\n",
      "          [-2.1092e-02,  3.7956e-02, -2.1998e-02],\n",
      "          [ 2.7844e-02,  3.2861e-02, -6.7756e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9826e-02,  1.5959e-02, -8.9596e-03],\n",
      "          [-3.9539e-02,  8.2210e-03, -2.1265e-02],\n",
      "          [-2.2960e-02, -3.4437e-02, -1.2456e-02]],\n",
      "\n",
      "         [[-3.1463e-02, -2.5100e-02,  3.5632e-02],\n",
      "          [-2.5355e-02,  3.2821e-02,  8.9760e-03],\n",
      "          [ 3.1625e-02,  2.5002e-02, -2.4008e-02]],\n",
      "\n",
      "         [[-1.2196e-02, -3.7597e-02, -3.0312e-02],\n",
      "          [ 4.1022e-02,  2.9156e-02, -2.5198e-02],\n",
      "          [-6.1735e-03,  3.3250e-02,  2.5950e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5788e-02, -1.7743e-02,  2.6196e-03],\n",
      "          [ 1.6882e-02,  3.3795e-02,  2.1578e-02],\n",
      "          [-3.8187e-02,  2.8518e-02,  3.3627e-02]],\n",
      "\n",
      "         [[ 1.7946e-02,  2.9851e-02,  1.0029e-03],\n",
      "          [-1.2813e-02, -1.6750e-02, -4.1408e-02],\n",
      "          [-3.2747e-02,  2.6740e-02, -1.4922e-02]],\n",
      "\n",
      "         [[-3.8597e-02, -3.2412e-02, -5.6084e-04],\n",
      "          [ 4.8335e-03, -4.8643e-03, -7.9984e-03],\n",
      "          [ 2.8662e-02, -5.6907e-03,  2.8675e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.5618e-02, -2.8167e-02,  2.0809e-02],\n",
      "          [-1.3730e-02,  1.1088e-02, -3.4468e-02],\n",
      "          [-7.3223e-03, -3.2443e-02, -6.0307e-03]],\n",
      "\n",
      "         [[ 1.8542e-02, -1.2269e-03,  2.2135e-02],\n",
      "          [-3.5218e-02,  1.8397e-02,  3.5695e-03],\n",
      "          [-8.8425e-03, -1.2308e-02, -2.2625e-03]],\n",
      "\n",
      "         [[-2.0155e-02, -1.7234e-02,  2.3514e-02],\n",
      "          [-3.2776e-02, -2.1486e-02,  1.3075e-02],\n",
      "          [-2.2143e-02, -2.8265e-02, -1.6156e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.5811e-02,  1.1253e-02, -2.9150e-02],\n",
      "          [-1.8478e-02,  2.7859e-02, -7.6124e-03],\n",
      "          [-2.6660e-02, -2.0046e-02, -1.7366e-02]],\n",
      "\n",
      "         [[-9.4682e-03,  1.4572e-02, -6.5633e-03],\n",
      "          [ 4.2701e-03, -5.9749e-03,  2.2506e-02],\n",
      "          [ 1.2138e-02, -2.5854e-02, -2.9945e-02]],\n",
      "\n",
      "         [[ 1.2062e-02, -2.4184e-02, -5.3387e-03],\n",
      "          [-2.0691e-02, -3.4808e-02,  1.6528e-02],\n",
      "          [ 1.4991e-02,  1.2876e-02, -1.9978e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0846e-02,  1.4786e-02, -1.0720e-02],\n",
      "          [ 8.0954e-03,  9.4653e-03, -3.3534e-02],\n",
      "          [ 9.4981e-03,  1.9360e-02, -2.0147e-02]],\n",
      "\n",
      "         [[-3.8680e-02, -2.8597e-02,  3.4637e-03],\n",
      "          [-1.3787e-02, -1.8843e-03, -2.3097e-02],\n",
      "          [ 1.2170e-02, -3.5904e-02, -2.9085e-02]],\n",
      "\n",
      "         [[-6.2491e-04, -2.1464e-02, -1.7386e-02],\n",
      "          [ 2.2406e-02,  2.1985e-02, -3.0101e-02],\n",
      "          [ 1.8470e-03, -1.7011e-02,  1.9370e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 7.5750e-03, -3.8732e-02, -2.2519e-02],\n",
      "          [ 2.7326e-02, -2.3791e-02,  9.4123e-04],\n",
      "          [-3.8734e-02,  3.8856e-02, -1.9059e-02]],\n",
      "\n",
      "         [[-7.1186e-03, -1.7565e-02, -2.8326e-02],\n",
      "          [ 9.1503e-03,  2.8039e-04, -3.9462e-02],\n",
      "          [ 2.5251e-02, -1.5501e-02, -1.5849e-02]],\n",
      "\n",
      "         [[ 2.8996e-02, -3.4742e-02,  3.2133e-02],\n",
      "          [ 2.7929e-02,  2.8085e-02, -8.4921e-03],\n",
      "          [ 2.2216e-04, -2.6309e-02,  3.5016e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.5817e-02, -2.1442e-03, -3.2282e-02],\n",
      "          [-2.4111e-03,  3.1597e-02, -1.5464e-03],\n",
      "          [-2.9412e-02,  1.3307e-02,  4.0471e-02]],\n",
      "\n",
      "         [[-9.8344e-03, -2.6977e-03,  7.2665e-03],\n",
      "          [-2.8365e-02,  3.2827e-02,  1.4851e-02],\n",
      "          [ 1.3898e-02, -3.8931e-02,  2.1843e-02]],\n",
      "\n",
      "         [[ 1.7714e-02, -2.5840e-02,  2.9079e-02],\n",
      "          [-2.8346e-02, -1.6286e-02, -3.0983e-02],\n",
      "          [-3.1826e-02,  4.0049e-02,  3.5121e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.7508e-02, -1.0623e-02,  3.6219e-02],\n",
      "          [-4.0087e-02, -4.3628e-03, -4.0552e-02],\n",
      "          [-1.5225e-02,  3.9575e-02,  6.0274e-03]],\n",
      "\n",
      "         [[-2.9065e-02, -2.5821e-02, -8.9812e-03],\n",
      "          [ 3.1191e-02, -3.5425e-02,  3.6425e-02],\n",
      "          [-3.2034e-02, -3.2204e-02,  1.2213e-02]],\n",
      "\n",
      "         [[-8.4389e-03,  1.1896e-02, -2.9083e-02],\n",
      "          [-4.1340e-02,  1.7751e-02,  9.3980e-03],\n",
      "          [ 3.6866e-02,  2.6498e-02,  2.4239e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.1000e-02, -2.3663e-02, -2.1118e-02],\n",
      "          [ 2.0668e-02,  2.1988e-02,  1.7548e-02],\n",
      "          [ 2.9782e-02, -5.9266e-03, -2.6020e-02]],\n",
      "\n",
      "         [[-2.0795e-03, -1.5314e-02,  4.0423e-02],\n",
      "          [-3.2083e-02,  1.8507e-02,  3.7990e-02],\n",
      "          [-1.6835e-02, -9.6987e-03, -1.1607e-02]],\n",
      "\n",
      "         [[-1.7256e-02, -3.7770e-02, -3.5838e-02],\n",
      "          [ 4.6454e-03,  1.6451e-02,  2.3307e-02],\n",
      "          [ 1.1788e-02, -3.9586e-02,  2.3473e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.7873e-02,  2.6887e-02, -2.6988e-02],\n",
      "          [ 3.2473e-02,  2.2317e-03,  9.3901e-03],\n",
      "          [-3.1783e-02, -6.0011e-03, -2.9374e-02]],\n",
      "\n",
      "         [[ 2.6762e-02, -3.9896e-02, -2.8171e-02],\n",
      "          [-2.2067e-02,  1.7486e-02, -4.0893e-02],\n",
      "          [ 9.5326e-03, -3.6918e-02,  1.9970e-02]],\n",
      "\n",
      "         [[-3.0405e-02,  2.8014e-06, -2.3199e-02],\n",
      "          [-3.5432e-02, -1.1060e-02, -1.8468e-02],\n",
      "          [-2.0510e-02, -2.9324e-02, -2.7562e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.7655e-02, -1.4784e-02, -3.0369e-02],\n",
      "          [-3.8928e-02,  8.9225e-03, -2.2826e-02],\n",
      "          [ 3.7018e-02,  2.6165e-02, -3.4346e-03]],\n",
      "\n",
      "         [[-1.7682e-02,  3.4674e-02,  1.1661e-02],\n",
      "          [ 4.0372e-02,  3.7551e-02,  2.7609e-02],\n",
      "          [ 2.3767e-03,  2.1952e-02,  2.9135e-02]],\n",
      "\n",
      "         [[-3.7189e-02,  2.8190e-02,  2.8057e-02],\n",
      "          [ 3.4938e-02, -1.6518e-02,  2.6905e-02],\n",
      "          [-1.6916e-02,  3.6238e-02, -3.6827e-02]]]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "torch.Size([128, 64, 3, 3])\n",
      "\n",
      "\n",
      "7th parameter:Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', requires_grad=True)\n",
      "torch.Size([128])\n",
      "\n",
      "\n",
      "8th parameter:Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n",
      "torch.Size([128])\n",
      "\n",
      "\n",
      "9th parameter:Parameter containing:\n",
      "tensor([[[[-5.8924e-03,  4.3713e-03,  2.7838e-02],\n",
      "          [-2.0504e-02,  7.0046e-04, -8.8613e-03],\n",
      "          [-1.1779e-02, -7.1659e-03,  1.0670e-02]],\n",
      "\n",
      "         [[-7.7303e-03, -7.5363e-03,  1.2014e-03],\n",
      "          [ 7.4282e-03, -2.4611e-02, -1.2325e-02],\n",
      "          [ 6.3495e-03,  2.6520e-02,  8.6441e-03]],\n",
      "\n",
      "         [[-6.3416e-03,  2.5241e-02,  2.4803e-03],\n",
      "          [-2.8045e-02, -3.9871e-03, -5.1910e-05],\n",
      "          [-2.7130e-02,  1.3686e-02,  8.5018e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.8986e-03, -6.1998e-03,  1.7158e-03],\n",
      "          [ 4.5038e-03, -2.0180e-02,  2.4651e-02],\n",
      "          [-5.9222e-03, -1.1677e-02, -2.5130e-03]],\n",
      "\n",
      "         [[-1.1608e-02, -1.0887e-02, -1.8865e-02],\n",
      "          [-1.8059e-02, -2.2422e-03, -1.9172e-02],\n",
      "          [-1.4526e-02, -1.6278e-02, -2.9353e-04]],\n",
      "\n",
      "         [[-1.7518e-02, -7.3428e-03, -1.1135e-02],\n",
      "          [-2.7627e-02,  1.4399e-02, -2.2841e-02],\n",
      "          [ 1.1276e-02, -9.6139e-03,  2.3320e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.8528e-02, -7.5882e-04,  2.4482e-02],\n",
      "          [ 9.9969e-03, -9.6238e-03,  2.2857e-02],\n",
      "          [ 1.0693e-02,  2.4203e-03,  4.5370e-03]],\n",
      "\n",
      "         [[-2.3655e-02, -2.6069e-02,  1.7043e-02],\n",
      "          [-2.3617e-02,  1.1532e-02,  2.6778e-02],\n",
      "          [-2.4292e-02, -8.2956e-03,  2.6042e-02]],\n",
      "\n",
      "         [[-2.0718e-03, -9.1187e-03, -7.5376e-03],\n",
      "          [-2.0177e-02, -1.0137e-02, -1.7356e-02],\n",
      "          [-2.1301e-02,  1.3869e-02, -1.9395e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.9019e-02, -2.6420e-02,  4.8146e-03],\n",
      "          [-1.4225e-02,  2.0417e-02, -1.4256e-02],\n",
      "          [ 1.7753e-02, -2.5567e-02,  5.8787e-03]],\n",
      "\n",
      "         [[-2.1114e-02,  1.8604e-02, -2.4558e-02],\n",
      "          [-2.1415e-02, -9.7487e-03,  1.2867e-02],\n",
      "          [ 2.4915e-02,  2.6786e-02, -1.6266e-02]],\n",
      "\n",
      "         [[-1.2468e-02, -1.5945e-02, -2.4248e-02],\n",
      "          [ 9.8930e-03, -1.5721e-03, -7.7744e-03],\n",
      "          [ 1.5775e-02, -2.9435e-04,  1.5082e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5388e-02, -1.1671e-02, -2.4562e-02],\n",
      "          [ 1.0217e-02, -2.9521e-03, -2.1111e-02],\n",
      "          [ 9.0890e-03,  1.3388e-02, -1.3210e-02]],\n",
      "\n",
      "         [[-3.1369e-03,  1.3963e-02,  1.3286e-02],\n",
      "          [ 8.8469e-03,  1.6772e-02,  2.8187e-02],\n",
      "          [-2.5257e-03, -2.6618e-03,  1.9793e-02]],\n",
      "\n",
      "         [[ 4.1398e-03, -4.5686e-03, -1.7689e-02],\n",
      "          [ 2.8828e-03,  8.3825e-03, -1.4370e-02],\n",
      "          [-1.8927e-02,  3.5589e-03, -9.1098e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.2202e-02,  2.4928e-02, -2.7088e-02],\n",
      "          [ 2.0775e-02,  2.6444e-02,  2.6462e-02],\n",
      "          [ 1.7747e-02, -1.3163e-02,  4.5853e-03]],\n",
      "\n",
      "         [[-2.0947e-02, -2.5711e-02, -3.9387e-03],\n",
      "          [ 2.3652e-02, -1.8116e-02,  9.6407e-03],\n",
      "          [-2.5511e-02, -6.5225e-04,  2.7514e-02]],\n",
      "\n",
      "         [[ 2.1474e-02,  2.1827e-02,  2.3930e-02],\n",
      "          [-2.1492e-02, -3.3576e-04,  2.5529e-02],\n",
      "          [ 7.3516e-03, -2.9504e-03,  1.7022e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.8081e-02, -3.3799e-03,  6.7376e-03],\n",
      "          [-6.5102e-03,  1.2422e-02,  1.5611e-02],\n",
      "          [ 5.2196e-03, -2.5900e-03,  2.3581e-02]],\n",
      "\n",
      "         [[ 1.5771e-02, -1.5126e-02,  1.6419e-02],\n",
      "          [ 1.0267e-02,  2.4654e-02, -2.7143e-02],\n",
      "          [ 2.9926e-03,  2.1818e-02,  1.3148e-02]],\n",
      "\n",
      "         [[ 4.8534e-03, -2.4037e-02,  2.7763e-02],\n",
      "          [-5.5363e-03,  1.5240e-02, -2.9238e-02],\n",
      "          [-1.9801e-02,  1.4425e-02, -9.9517e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3641e-02,  2.7074e-02, -1.3297e-02],\n",
      "          [-2.6320e-02, -1.3771e-02,  1.7644e-03],\n",
      "          [-7.3307e-03,  1.9525e-02,  2.7414e-02]],\n",
      "\n",
      "         [[-1.2565e-02, -3.2061e-03,  2.1869e-02],\n",
      "          [ 1.0627e-02, -3.9240e-03,  1.3433e-04],\n",
      "          [ 2.8290e-02, -2.4914e-02, -1.8832e-02]],\n",
      "\n",
      "         [[-2.5612e-02, -1.1160e-02, -1.1811e-02],\n",
      "          [-5.4393e-03, -2.1166e-02, -3.7492e-03],\n",
      "          [-1.9263e-02,  2.9175e-02, -3.6119e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.3893e-03, -8.3420e-03,  2.0198e-02],\n",
      "          [ 8.0577e-03, -1.6413e-02,  1.8834e-02],\n",
      "          [ 2.7592e-02,  2.3378e-02, -1.8148e-02]],\n",
      "\n",
      "         [[-5.5560e-04,  7.9048e-03,  6.8234e-03],\n",
      "          [-1.5948e-02, -1.0735e-02,  1.2929e-02],\n",
      "          [-1.1020e-02, -1.7486e-02,  2.1221e-02]],\n",
      "\n",
      "         [[-2.5194e-02, -5.4845e-03,  2.4966e-02],\n",
      "          [-2.1405e-02,  1.8099e-02, -1.8109e-02],\n",
      "          [ 1.3069e-02,  6.3686e-03,  1.6424e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0467e-02,  1.0859e-02,  1.8107e-02],\n",
      "          [ 2.5908e-02, -7.7811e-03, -9.5500e-03],\n",
      "          [ 2.6041e-02,  2.4989e-03,  1.7052e-02]],\n",
      "\n",
      "         [[ 2.6646e-02, -2.4181e-02,  2.2928e-02],\n",
      "          [-4.6732e-03, -2.8883e-02, -1.5757e-02],\n",
      "          [-5.1967e-03,  6.6477e-03, -1.0852e-02]],\n",
      "\n",
      "         [[-2.6181e-02, -1.3256e-02,  1.4505e-02],\n",
      "          [-2.2148e-02, -1.7632e-03, -4.4103e-03],\n",
      "          [-1.1157e-02, -1.9813e-02,  3.1114e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6847e-02,  2.1879e-02, -3.6840e-03],\n",
      "          [ 1.4462e-02, -3.4930e-03,  2.6856e-02],\n",
      "          [ 3.7677e-03, -1.1072e-02, -2.1470e-02]],\n",
      "\n",
      "         [[-5.4887e-03, -2.4555e-02, -2.4079e-02],\n",
      "          [ 1.5819e-02, -1.9126e-02, -2.0243e-02],\n",
      "          [ 1.7830e-02, -2.8161e-02, -2.4384e-02]],\n",
      "\n",
      "         [[-2.8758e-02, -1.3106e-02, -1.9256e-02],\n",
      "          [-1.8833e-02,  2.5222e-02,  1.8687e-02],\n",
      "          [-1.2191e-02,  9.4318e-03,  4.5779e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.8840e-02,  1.7797e-02, -2.4251e-02],\n",
      "          [ 4.9980e-03, -1.1772e-02,  1.4625e-02],\n",
      "          [-2.4430e-02, -1.1844e-02, -4.6299e-03]],\n",
      "\n",
      "         [[-1.0011e-02,  1.2055e-02,  1.6250e-02],\n",
      "          [-3.3451e-03, -1.3530e-02,  2.6783e-02],\n",
      "          [ 8.0442e-03,  1.7221e-02,  1.7596e-02]],\n",
      "\n",
      "         [[ 6.4485e-03,  1.4531e-02,  1.9160e-02],\n",
      "          [-1.2474e-02,  1.4629e-02, -1.1877e-02],\n",
      "          [ 1.7035e-02,  2.0495e-02,  4.9314e-03]]]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "torch.Size([128, 128, 3, 3])\n",
      "\n",
      "\n",
      "10th parameter:Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', requires_grad=True)\n",
      "torch.Size([128])\n",
      "\n",
      "\n",
      "11th parameter:Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n",
      "torch.Size([128])\n",
      "\n",
      "\n",
      "12th parameter:Parameter containing:\n",
      "tensor([[[[ 0.1480, -0.0949, -0.0430],\n",
      "          [-0.1179, -0.0253, -0.0981],\n",
      "          [ 0.0064, -0.1170,  0.0759]],\n",
      "\n",
      "         [[-0.1664, -0.0165,  0.1873],\n",
      "          [ 0.1801,  0.1775,  0.0070],\n",
      "          [-0.1805,  0.0129, -0.1137]],\n",
      "\n",
      "         [[-0.1770, -0.0191,  0.0171],\n",
      "          [ 0.1148,  0.0992, -0.0588],\n",
      "          [-0.0177, -0.0566,  0.1261]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1091,  0.0456, -0.1222],\n",
      "          [-0.1854,  0.1085, -0.0525],\n",
      "          [-0.0331, -0.0106, -0.0916]],\n",
      "\n",
      "         [[ 0.1205, -0.0659,  0.0869],\n",
      "          [ 0.0130,  0.0085,  0.1342],\n",
      "          [-0.1442,  0.0938, -0.1135]],\n",
      "\n",
      "         [[-0.0221,  0.1435, -0.1227],\n",
      "          [-0.1248, -0.1870,  0.0810],\n",
      "          [ 0.1423, -0.1855,  0.1415]]],\n",
      "\n",
      "\n",
      "        [[[-0.1420,  0.0443, -0.1363],\n",
      "          [-0.0024, -0.1476, -0.1357],\n",
      "          [-0.1704,  0.0106, -0.0321]],\n",
      "\n",
      "         [[-0.0317, -0.0503, -0.1206],\n",
      "          [ 0.0353,  0.0292, -0.0076],\n",
      "          [ 0.0542, -0.0749,  0.1157]],\n",
      "\n",
      "         [[ 0.1257, -0.1801,  0.0545],\n",
      "          [-0.0690, -0.0588, -0.0745],\n",
      "          [ 0.1600,  0.1520,  0.1567]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0986, -0.1455, -0.0991],\n",
      "          [ 0.1506, -0.0386,  0.0083],\n",
      "          [-0.0733, -0.1809, -0.0518]],\n",
      "\n",
      "         [[ 0.1426, -0.1455, -0.1409],\n",
      "          [-0.1667, -0.0967, -0.0136],\n",
      "          [-0.1595, -0.1451, -0.0198]],\n",
      "\n",
      "         [[ 0.1114,  0.0511, -0.0418],\n",
      "          [-0.0398, -0.0783,  0.0561],\n",
      "          [ 0.0441, -0.1678,  0.1341]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1671, -0.1861, -0.1454],\n",
      "          [-0.1656,  0.0148,  0.0778],\n",
      "          [-0.1694, -0.1497,  0.1292]],\n",
      "\n",
      "         [[-0.1209, -0.1218, -0.1491],\n",
      "          [ 0.0749,  0.0587, -0.1324],\n",
      "          [-0.1063,  0.0160, -0.1451]],\n",
      "\n",
      "         [[ 0.0241, -0.1067,  0.1216],\n",
      "          [-0.1636,  0.1436,  0.0459],\n",
      "          [-0.1043, -0.0688,  0.1148]]],\n",
      "\n",
      "\n",
      "        [[[-0.0089, -0.0378, -0.1812],\n",
      "          [-0.0230, -0.0997, -0.0936],\n",
      "          [ 0.0656, -0.1038, -0.1908]],\n",
      "\n",
      "         [[ 0.1384,  0.0110, -0.0918],\n",
      "          [ 0.0363,  0.0311, -0.1187],\n",
      "          [ 0.0221, -0.0578, -0.1857]],\n",
      "\n",
      "         [[ 0.1518,  0.0527,  0.0936],\n",
      "          [-0.1180,  0.1873,  0.0677],\n",
      "          [-0.0225, -0.0587, -0.0463]]]], device='cuda:0', requires_grad=True)\n",
      "torch.Size([64, 3, 3, 3])\n",
      "\n",
      "\n",
      "13th parameter:Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "torch.Size([64])\n",
      "\n",
      "\n",
      "14th parameter:Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "torch.Size([64])\n",
      "\n",
      "\n",
      "15th parameter:Parameter containing:\n",
      "tensor([[[[-0.0389, -0.0252, -0.0296],\n",
      "          [ 0.0194, -0.0026, -0.0340],\n",
      "          [-0.0137, -0.0380, -0.0397]],\n",
      "\n",
      "         [[ 0.0182, -0.0014,  0.0111],\n",
      "          [ 0.0228, -0.0293,  0.0348],\n",
      "          [ 0.0045,  0.0241,  0.0272]],\n",
      "\n",
      "         [[-0.0134,  0.0175,  0.0307],\n",
      "          [ 0.0001,  0.0066,  0.0271],\n",
      "          [-0.0085,  0.0137,  0.0398]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0326,  0.0243, -0.0132],\n",
      "          [-0.0150, -0.0159, -0.0026],\n",
      "          [-0.0084, -0.0285, -0.0069]],\n",
      "\n",
      "         [[-0.0368,  0.0271,  0.0114],\n",
      "          [ 0.0119,  0.0154, -0.0284],\n",
      "          [ 0.0285,  0.0203, -0.0356]],\n",
      "\n",
      "         [[ 0.0132,  0.0177, -0.0202],\n",
      "          [-0.0170,  0.0146, -0.0354],\n",
      "          [ 0.0392, -0.0141,  0.0135]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0309, -0.0297,  0.0052],\n",
      "          [ 0.0119,  0.0191,  0.0016],\n",
      "          [ 0.0113, -0.0321, -0.0245]],\n",
      "\n",
      "         [[ 0.0146,  0.0085,  0.0395],\n",
      "          [-0.0139, -0.0253, -0.0388],\n",
      "          [-0.0103, -0.0208, -0.0033]],\n",
      "\n",
      "         [[-0.0227, -0.0004, -0.0156],\n",
      "          [-0.0397,  0.0154,  0.0242],\n",
      "          [-0.0088,  0.0273, -0.0028]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0087,  0.0307,  0.0120],\n",
      "          [ 0.0316, -0.0299,  0.0357],\n",
      "          [ 0.0089, -0.0266,  0.0217]],\n",
      "\n",
      "         [[ 0.0126,  0.0141, -0.0325],\n",
      "          [-0.0161, -0.0158, -0.0329],\n",
      "          [-0.0324,  0.0299, -0.0075]],\n",
      "\n",
      "         [[-0.0296,  0.0171, -0.0223],\n",
      "          [ 0.0387, -0.0027,  0.0153],\n",
      "          [-0.0305,  0.0122, -0.0261]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0330,  0.0158, -0.0160],\n",
      "          [ 0.0362,  0.0361,  0.0308],\n",
      "          [-0.0159,  0.0034, -0.0290]],\n",
      "\n",
      "         [[ 0.0379, -0.0116,  0.0130],\n",
      "          [-0.0333, -0.0170, -0.0010],\n",
      "          [ 0.0404,  0.0084, -0.0143]],\n",
      "\n",
      "         [[-0.0099,  0.0290, -0.0190],\n",
      "          [-0.0205, -0.0017,  0.0319],\n",
      "          [-0.0215, -0.0393,  0.0288]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0012, -0.0060,  0.0029],\n",
      "          [ 0.0291,  0.0317, -0.0047],\n",
      "          [-0.0052, -0.0340, -0.0269]],\n",
      "\n",
      "         [[-0.0383, -0.0134,  0.0358],\n",
      "          [-0.0211,  0.0254, -0.0145],\n",
      "          [ 0.0334,  0.0135, -0.0373]],\n",
      "\n",
      "         [[ 0.0067, -0.0154,  0.0111],\n",
      "          [-0.0398,  0.0098,  0.0279],\n",
      "          [-0.0144, -0.0011, -0.0400]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0017,  0.0004,  0.0342],\n",
      "          [-0.0250,  0.0088,  0.0066],\n",
      "          [-0.0206, -0.0365,  0.0056]],\n",
      "\n",
      "         [[ 0.0409,  0.0178,  0.0361],\n",
      "          [ 0.0026,  0.0110,  0.0358],\n",
      "          [-0.0180, -0.0214,  0.0122]],\n",
      "\n",
      "         [[-0.0294,  0.0173, -0.0306],\n",
      "          [-0.0388,  0.0368, -0.0184],\n",
      "          [-0.0159, -0.0268,  0.0127]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0246,  0.0096, -0.0414],\n",
      "          [-0.0279, -0.0371, -0.0085],\n",
      "          [-0.0117, -0.0246, -0.0075]],\n",
      "\n",
      "         [[-0.0033, -0.0241, -0.0354],\n",
      "          [ 0.0268, -0.0317,  0.0138],\n",
      "          [-0.0008,  0.0048, -0.0040]],\n",
      "\n",
      "         [[ 0.0008, -0.0026, -0.0086],\n",
      "          [-0.0305,  0.0322, -0.0382],\n",
      "          [ 0.0266,  0.0317,  0.0127]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0035, -0.0181, -0.0052],\n",
      "          [-0.0070, -0.0106,  0.0095],\n",
      "          [-0.0087, -0.0374, -0.0234]],\n",
      "\n",
      "         [[-0.0085,  0.0027, -0.0184],\n",
      "          [-0.0105,  0.0057, -0.0150],\n",
      "          [-0.0121, -0.0348,  0.0385]],\n",
      "\n",
      "         [[-0.0057, -0.0290,  0.0275],\n",
      "          [ 0.0392, -0.0175, -0.0168],\n",
      "          [ 0.0140,  0.0072,  0.0306]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0291, -0.0039, -0.0212],\n",
      "          [ 0.0033, -0.0354, -0.0064],\n",
      "          [ 0.0052, -0.0375,  0.0155]],\n",
      "\n",
      "         [[-0.0107,  0.0411, -0.0251],\n",
      "          [ 0.0236,  0.0040, -0.0186],\n",
      "          [-0.0118,  0.0078,  0.0404]],\n",
      "\n",
      "         [[ 0.0355,  0.0272,  0.0292],\n",
      "          [-0.0248,  0.0261, -0.0294],\n",
      "          [ 0.0025, -0.0229,  0.0120]]],\n",
      "\n",
      "\n",
      "        [[[-0.0306, -0.0145, -0.0370],\n",
      "          [-0.0100, -0.0179,  0.0165],\n",
      "          [ 0.0164, -0.0227, -0.0069]],\n",
      "\n",
      "         [[-0.0026, -0.0144, -0.0100],\n",
      "          [ 0.0010, -0.0004,  0.0414],\n",
      "          [ 0.0278,  0.0279, -0.0067]],\n",
      "\n",
      "         [[-0.0112, -0.0064,  0.0226],\n",
      "          [ 0.0299,  0.0071, -0.0170],\n",
      "          [-0.0170, -0.0169, -0.0079]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0071,  0.0296,  0.0155],\n",
      "          [-0.0102,  0.0216, -0.0195],\n",
      "          [-0.0160, -0.0216, -0.0348]],\n",
      "\n",
      "         [[ 0.0276,  0.0020,  0.0280],\n",
      "          [ 0.0296, -0.0166,  0.0039],\n",
      "          [ 0.0169,  0.0175,  0.0186]],\n",
      "\n",
      "         [[ 0.0054, -0.0055, -0.0200],\n",
      "          [ 0.0030,  0.0279,  0.0353],\n",
      "          [ 0.0123,  0.0193,  0.0291]]]], device='cuda:0', requires_grad=True)\n",
      "torch.Size([64, 64, 3, 3])\n",
      "\n",
      "\n",
      "16th parameter:Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "torch.Size([64])\n",
      "\n",
      "\n",
      "17th parameter:Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "torch.Size([64])\n",
      "\n",
      "\n",
      "18th parameter:Parameter containing:\n",
      "tensor([[[[ 0.0104,  0.0210,  0.0059],\n",
      "          [-0.0063, -0.0046,  0.0022],\n",
      "          [-0.0242, -0.0205,  0.0243]],\n",
      "\n",
      "         [[-0.0149,  0.0301, -0.0279],\n",
      "          [-0.0116,  0.0275,  0.0040],\n",
      "          [-0.0331, -0.0254,  0.0323]],\n",
      "\n",
      "         [[ 0.0335, -0.0026,  0.0127],\n",
      "          [-0.0212, -0.0055, -0.0219],\n",
      "          [ 0.0134, -0.0169, -0.0148]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0183,  0.0061, -0.0221],\n",
      "          [-0.0235,  0.0292, -0.0223],\n",
      "          [ 0.0067,  0.0257, -0.0363]],\n",
      "\n",
      "         [[-0.0057,  0.0244, -0.0043],\n",
      "          [ 0.0223, -0.0335,  0.0089],\n",
      "          [-0.0357,  0.0033, -0.0204]],\n",
      "\n",
      "         [[-0.0413,  0.0381,  0.0022],\n",
      "          [-0.0054,  0.0228,  0.0054],\n",
      "          [ 0.0279, -0.0214,  0.0271]]],\n",
      "\n",
      "\n",
      "        [[[-0.0166,  0.0020,  0.0145],\n",
      "          [-0.0301,  0.0209, -0.0371],\n",
      "          [ 0.0379, -0.0097, -0.0114]],\n",
      "\n",
      "         [[ 0.0095, -0.0086, -0.0289],\n",
      "          [-0.0017, -0.0259,  0.0143],\n",
      "          [-0.0152,  0.0155, -0.0334]],\n",
      "\n",
      "         [[-0.0161,  0.0101, -0.0214],\n",
      "          [ 0.0079, -0.0099,  0.0119],\n",
      "          [ 0.0258,  0.0292,  0.0171]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0048,  0.0163,  0.0406],\n",
      "          [ 0.0022,  0.0064, -0.0100],\n",
      "          [-0.0214,  0.0238, -0.0203]],\n",
      "\n",
      "         [[-0.0225, -0.0105, -0.0406],\n",
      "          [-0.0255,  0.0165,  0.0392],\n",
      "          [-0.0274,  0.0367,  0.0250]],\n",
      "\n",
      "         [[-0.0259,  0.0348, -0.0006],\n",
      "          [-0.0188, -0.0211,  0.0318],\n",
      "          [-0.0398, -0.0159, -0.0356]]],\n",
      "\n",
      "\n",
      "        [[[-0.0293,  0.0213,  0.0216],\n",
      "          [-0.0018,  0.0098, -0.0105],\n",
      "          [-0.0239,  0.0234, -0.0219]],\n",
      "\n",
      "         [[ 0.0369,  0.0314, -0.0183],\n",
      "          [-0.0374,  0.0162, -0.0408],\n",
      "          [-0.0006, -0.0237, -0.0089]],\n",
      "\n",
      "         [[ 0.0091, -0.0072,  0.0007],\n",
      "          [-0.0364,  0.0171,  0.0364],\n",
      "          [ 0.0017,  0.0025,  0.0334]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0397, -0.0026,  0.0353],\n",
      "          [ 0.0230,  0.0206, -0.0390],\n",
      "          [ 0.0301, -0.0221, -0.0080]],\n",
      "\n",
      "         [[ 0.0267, -0.0345, -0.0336],\n",
      "          [-0.0397,  0.0137, -0.0268],\n",
      "          [ 0.0231, -0.0012,  0.0381]],\n",
      "\n",
      "         [[ 0.0140, -0.0080, -0.0114],\n",
      "          [-0.0359, -0.0387,  0.0313],\n",
      "          [ 0.0005, -0.0086, -0.0204]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0279,  0.0203,  0.0164],\n",
      "          [-0.0137, -0.0189,  0.0079],\n",
      "          [-0.0380,  0.0353,  0.0172]],\n",
      "\n",
      "         [[ 0.0327, -0.0298,  0.0183],\n",
      "          [ 0.0014,  0.0196,  0.0277],\n",
      "          [-0.0295,  0.0080, -0.0208]],\n",
      "\n",
      "         [[ 0.0191, -0.0411, -0.0397],\n",
      "          [ 0.0075,  0.0105,  0.0414],\n",
      "          [ 0.0231,  0.0032,  0.0149]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0368, -0.0295, -0.0278],\n",
      "          [ 0.0066,  0.0183,  0.0169],\n",
      "          [ 0.0143, -0.0138,  0.0059]],\n",
      "\n",
      "         [[ 0.0307,  0.0373,  0.0197],\n",
      "          [-0.0270,  0.0206,  0.0266],\n",
      "          [ 0.0226,  0.0047, -0.0107]],\n",
      "\n",
      "         [[ 0.0270, -0.0397, -0.0297],\n",
      "          [ 0.0346, -0.0004,  0.0035],\n",
      "          [ 0.0253,  0.0045, -0.0146]]],\n",
      "\n",
      "\n",
      "        [[[-0.0362, -0.0257, -0.0133],\n",
      "          [ 0.0331, -0.0133, -0.0174],\n",
      "          [ 0.0154,  0.0377,  0.0214]],\n",
      "\n",
      "         [[-0.0314,  0.0004, -0.0416],\n",
      "          [ 0.0192,  0.0174, -0.0203],\n",
      "          [ 0.0201, -0.0149, -0.0224]],\n",
      "\n",
      "         [[ 0.0262,  0.0038,  0.0022],\n",
      "          [-0.0355,  0.0155, -0.0374],\n",
      "          [-0.0166,  0.0195,  0.0253]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0391,  0.0374,  0.0319],\n",
      "          [-0.0329, -0.0177, -0.0302],\n",
      "          [-0.0053,  0.0119, -0.0194]],\n",
      "\n",
      "         [[ 0.0284, -0.0358, -0.0239],\n",
      "          [ 0.0321,  0.0300,  0.0168],\n",
      "          [ 0.0227,  0.0001,  0.0040]],\n",
      "\n",
      "         [[ 0.0172,  0.0388, -0.0100],\n",
      "          [-0.0375,  0.0374,  0.0281],\n",
      "          [-0.0121, -0.0353, -0.0052]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0073,  0.0398,  0.0333],\n",
      "          [ 0.0133, -0.0129, -0.0090],\n",
      "          [ 0.0392, -0.0322,  0.0191]],\n",
      "\n",
      "         [[-0.0248,  0.0221, -0.0095],\n",
      "          [ 0.0377, -0.0169,  0.0175],\n",
      "          [-0.0409,  0.0268, -0.0172]],\n",
      "\n",
      "         [[-0.0399, -0.0222,  0.0132],\n",
      "          [ 0.0094,  0.0169, -0.0082],\n",
      "          [ 0.0088, -0.0025, -0.0221]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0094, -0.0322,  0.0302],\n",
      "          [-0.0390,  0.0254,  0.0162],\n",
      "          [ 0.0054, -0.0388,  0.0112]],\n",
      "\n",
      "         [[ 0.0267,  0.0242,  0.0045],\n",
      "          [-0.0173,  0.0260,  0.0142],\n",
      "          [ 0.0377, -0.0304,  0.0382]],\n",
      "\n",
      "         [[-0.0121, -0.0157, -0.0345],\n",
      "          [-0.0228,  0.0290,  0.0280],\n",
      "          [-0.0168, -0.0038,  0.0328]]]], device='cuda:0', requires_grad=True)\n",
      "torch.Size([128, 64, 3, 3])\n",
      "\n",
      "\n",
      "19th parameter:Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', requires_grad=True)\n",
      "torch.Size([128])\n",
      "\n",
      "\n",
      "20th parameter:Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n",
      "torch.Size([128])\n",
      "\n",
      "\n",
      "21th parameter:Parameter containing:\n",
      "tensor([[[[-0.0289,  0.0246, -0.0033],\n",
      "          [-0.0199,  0.0213, -0.0058],\n",
      "          [-0.0047,  0.0140,  0.0163]],\n",
      "\n",
      "         [[ 0.0108, -0.0087, -0.0266],\n",
      "          [ 0.0226,  0.0026, -0.0138],\n",
      "          [ 0.0132,  0.0026, -0.0180]],\n",
      "\n",
      "         [[ 0.0082,  0.0192,  0.0235],\n",
      "          [-0.0254, -0.0084,  0.0225],\n",
      "          [-0.0245,  0.0143, -0.0153]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0287,  0.0008, -0.0267],\n",
      "          [-0.0111, -0.0275,  0.0139],\n",
      "          [-0.0281, -0.0039, -0.0236]],\n",
      "\n",
      "         [[ 0.0260, -0.0141, -0.0201],\n",
      "          [ 0.0186,  0.0148,  0.0172],\n",
      "          [ 0.0056, -0.0196, -0.0075]],\n",
      "\n",
      "         [[-0.0040,  0.0144,  0.0049],\n",
      "          [-0.0196, -0.0149, -0.0177],\n",
      "          [ 0.0016,  0.0087,  0.0234]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0189, -0.0019, -0.0255],\n",
      "          [-0.0211,  0.0010, -0.0251],\n",
      "          [-0.0210,  0.0140, -0.0140]],\n",
      "\n",
      "         [[ 0.0023, -0.0093,  0.0047],\n",
      "          [ 0.0248,  0.0101, -0.0054],\n",
      "          [ 0.0205,  0.0158, -0.0117]],\n",
      "\n",
      "         [[-0.0067,  0.0119, -0.0168],\n",
      "          [ 0.0025, -0.0152,  0.0153],\n",
      "          [ 0.0083, -0.0171, -0.0081]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0047, -0.0006, -0.0031],\n",
      "          [-0.0087, -0.0092,  0.0280],\n",
      "          [-0.0204,  0.0017,  0.0024]],\n",
      "\n",
      "         [[-0.0013,  0.0090, -0.0007],\n",
      "          [-0.0097,  0.0252, -0.0031],\n",
      "          [ 0.0021,  0.0277,  0.0095]],\n",
      "\n",
      "         [[-0.0058,  0.0027, -0.0223],\n",
      "          [-0.0289,  0.0128, -0.0001],\n",
      "          [ 0.0107, -0.0230,  0.0040]]],\n",
      "\n",
      "\n",
      "        [[[-0.0206,  0.0237, -0.0227],\n",
      "          [-0.0173, -0.0008,  0.0062],\n",
      "          [-0.0072,  0.0139, -0.0017]],\n",
      "\n",
      "         [[ 0.0235, -0.0200, -0.0191],\n",
      "          [-0.0227,  0.0210, -0.0176],\n",
      "          [-0.0012, -0.0114, -0.0242]],\n",
      "\n",
      "         [[ 0.0023, -0.0108, -0.0152],\n",
      "          [-0.0261,  0.0142, -0.0018],\n",
      "          [ 0.0082, -0.0257, -0.0224]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0091,  0.0012,  0.0139],\n",
      "          [ 0.0231,  0.0165,  0.0052],\n",
      "          [-0.0195, -0.0043, -0.0192]],\n",
      "\n",
      "         [[-0.0102, -0.0004,  0.0105],\n",
      "          [ 0.0288,  0.0271,  0.0123],\n",
      "          [ 0.0189, -0.0157, -0.0036]],\n",
      "\n",
      "         [[-0.0281,  0.0008,  0.0037],\n",
      "          [-0.0009, -0.0220,  0.0071],\n",
      "          [-0.0003, -0.0210, -0.0222]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0048, -0.0234,  0.0015],\n",
      "          [-0.0100, -0.0194,  0.0096],\n",
      "          [-0.0001, -0.0040,  0.0285]],\n",
      "\n",
      "         [[ 0.0112, -0.0271, -0.0091],\n",
      "          [-0.0279, -0.0221, -0.0087],\n",
      "          [-0.0209, -0.0085, -0.0081]],\n",
      "\n",
      "         [[ 0.0152,  0.0113, -0.0226],\n",
      "          [ 0.0047,  0.0207,  0.0231],\n",
      "          [-0.0074, -0.0045, -0.0169]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0136,  0.0203,  0.0285],\n",
      "          [ 0.0137, -0.0006, -0.0164],\n",
      "          [ 0.0084,  0.0266,  0.0218]],\n",
      "\n",
      "         [[ 0.0193, -0.0260, -0.0166],\n",
      "          [-0.0291, -0.0211, -0.0239],\n",
      "          [ 0.0273,  0.0231,  0.0157]],\n",
      "\n",
      "         [[-0.0294, -0.0280,  0.0086],\n",
      "          [ 0.0212,  0.0066, -0.0174],\n",
      "          [-0.0279, -0.0012,  0.0216]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0082,  0.0088, -0.0211],\n",
      "          [ 0.0080,  0.0143, -0.0274],\n",
      "          [-0.0179, -0.0075, -0.0228]],\n",
      "\n",
      "         [[ 0.0250, -0.0233, -0.0094],\n",
      "          [ 0.0227, -0.0125,  0.0108],\n",
      "          [ 0.0216,  0.0276,  0.0061]],\n",
      "\n",
      "         [[-0.0194, -0.0262, -0.0214],\n",
      "          [ 0.0126, -0.0290, -0.0145],\n",
      "          [ 0.0178,  0.0107, -0.0107]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0032, -0.0074, -0.0165],\n",
      "          [-0.0144,  0.0046, -0.0155],\n",
      "          [-0.0033,  0.0132, -0.0257]],\n",
      "\n",
      "         [[-0.0034,  0.0203, -0.0186],\n",
      "          [-0.0174, -0.0099, -0.0224],\n",
      "          [ 0.0104, -0.0138,  0.0027]],\n",
      "\n",
      "         [[ 0.0291,  0.0204,  0.0230],\n",
      "          [ 0.0214, -0.0056, -0.0242],\n",
      "          [ 0.0220, -0.0023,  0.0186]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0260, -0.0201,  0.0247],\n",
      "          [-0.0281, -0.0069, -0.0077],\n",
      "          [-0.0187,  0.0284, -0.0018]],\n",
      "\n",
      "         [[-0.0005, -0.0293, -0.0291],\n",
      "          [-0.0245,  0.0158,  0.0184],\n",
      "          [ 0.0048, -0.0129,  0.0252]],\n",
      "\n",
      "         [[ 0.0268, -0.0203,  0.0031],\n",
      "          [ 0.0254,  0.0246, -0.0189],\n",
      "          [ 0.0065,  0.0159, -0.0067]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0032, -0.0155,  0.0226],\n",
      "          [ 0.0243, -0.0147,  0.0102],\n",
      "          [-0.0166, -0.0070, -0.0294]],\n",
      "\n",
      "         [[ 0.0181, -0.0187, -0.0052],\n",
      "          [-0.0158,  0.0278,  0.0021],\n",
      "          [-0.0222, -0.0162,  0.0120]],\n",
      "\n",
      "         [[-0.0213, -0.0036, -0.0262],\n",
      "          [ 0.0033,  0.0243,  0.0228],\n",
      "          [ 0.0050, -0.0209, -0.0027]]]], device='cuda:0', requires_grad=True)\n",
      "torch.Size([128, 128, 3, 3])\n",
      "\n",
      "\n",
      "22th parameter:Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], device='cuda:0', requires_grad=True)\n",
      "torch.Size([128])\n",
      "\n",
      "\n",
      "23th parameter:Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n",
      "torch.Size([128])\n",
      "\n",
      "\n",
      "24th parameter:Parameter containing:\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', requires_grad=True)\n",
      "torch.Size([10, 2048])\n",
      "\n",
      "\n",
      "25th parameter:Parameter containing:\n",
      "tensor([-0.0065, -0.0007,  0.0040,  0.0054,  0.0074, -0.0073, -0.0182, -0.0152,\n",
      "         0.0057, -0.0136], device='cuda:0', requires_grad=True)\n",
      "torch.Size([10])\n",
      "\n",
      "\n",
      "26th parameter:Parameter containing:\n",
      "tensor([[-0.0001, -0.0220,  0.0067,  ..., -0.0127,  0.0023, -0.0098],\n",
      "        [ 0.0151, -0.0005,  0.0195,  ..., -0.0201, -0.0019, -0.0219],\n",
      "        [ 0.0010, -0.0018,  0.0026,  ...,  0.0030,  0.0057, -0.0037],\n",
      "        ...,\n",
      "        [ 0.0080,  0.0159,  0.0193,  ...,  0.0002,  0.0025, -0.0013],\n",
      "        [-0.0004, -0.0031, -0.0119,  ...,  0.0066,  0.0018,  0.0196],\n",
      "        [-0.0182, -0.0167,  0.0086,  ..., -0.0177,  0.0161, -0.0175]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "torch.Size([10, 2048])\n",
      "\n",
      "\n",
      "27th parameter:Parameter containing:\n",
      "tensor([-0.0028, -0.0113, -0.0156, -0.0113, -0.0146,  0.0108, -0.0028, -0.0152,\n",
      "         0.0103,  0.0152], device='cuda:0', requires_grad=True)\n",
      "torch.Size([10])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params=list(model.parameters())\n",
    "print(params[0].size())\n",
    "print(params[12].size())\n",
    "for i in range(len(params)):\n",
    "    print(f'{i}th parameter:{params[i]}')\n",
    "    print(params[i].size()) \n",
    "    print(\"\\n\")\n",
    "# params[0]=params[0].view(params[0].size()[0],-1)\n",
    "# print(params[0].size())\n",
    "# # for i in range(64):\n",
    "# #     print(params[0][i])\n",
    "# print(params[0])\n",
    "# print(params[0][:,26].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 2])\n",
      "tensor([[1, 2, 3, 4],\n",
      "        [5, 6, 7, 8]])\n",
      "torch.Size([2, 4])\n",
      "tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]])\n",
      "torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([[[1, 2],\n",
    "                       [3, 4]],\n",
    "                      [[5, 6],\n",
    "                       [7, 8]]])\n",
    "print(t.size())\n",
    "# t.flatten_()\n",
    "# t=torch.flatten(t,start_dim=0)\n",
    "t=t.view(t.size()[0],-1)\n",
    "print(t)\n",
    "print(t.size())\n",
    "t=t.view(t.size()[0],2,2)\n",
    "print(t)\n",
    "print(t.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Custom Optimizer'''\n",
    "'''tiki-taka's asymmetric characteristic simulated here'''\n",
    "\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "# import copy\n",
    "from torch.nn.init import xavier_uniform_, zeros_\n",
    "# from torch.nn.modules.linear import reset_parameters\n",
    "\n",
    "class Tiki_Taka(Optimizer, Net):\n",
    "    \"\"\"Implements RPU based SGD algorithm\n",
    "    Parameters:...\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, params, lr = required, momentum =0, dampening =0, weight_decay=0, nesterov=False):\n",
    "        if lr is not required and lr < 0.0:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if momentum < 0.0:\n",
    "            raise ValueError(\"Invalid momentum value: {}\".format(momentum))\n",
    "        if weight_decay<0.0:\n",
    "            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n",
    "        \n",
    "        defaults = dict(lr=lr, momentum=momentum, dampening=dampening, weight_decay=weight_decay, nesterov=nesterov)\n",
    "        super(Tiki_Taka, self).__init__(params, defaults)\n",
    "        self.update_count = 0\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(Tiki_Taka, self).__setstate__(state)\n",
    "        \n",
    "#     ns=0\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        \"\"\"Performs a single optimization step\"\"\"\n",
    "        \n",
    "        loss =None\n",
    "        if closure is not None:\n",
    "            with torch.enable_grad():\n",
    "                loss = closure()\n",
    "        \n",
    "        for group in self.param_groups:\n",
    "            weight_decay = group['weight_decay']\n",
    "            momentum = group['momentum']\n",
    "            dampening = group['dampening']\n",
    "            nesterov = group['nesterov']\n",
    "        \n",
    "            counter=0\n",
    "            for p in group['params']:\n",
    "#                 import pdb;pdb.set_trace()\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                \n",
    "                d_p=p.grad\n",
    "\n",
    "                if counter in [0,3,6,9,24,25]:\n",
    "\n",
    "                    asym=1+1.66*p\n",
    "                    asym2=1-1.66*p\n",
    "                    new=F.relu(torch.sign(d_p), inplace=False)\n",
    "                    new2=F.relu(-torch.sign(d_p), inplace=False)\n",
    "                    mul = new.mul(asym)\n",
    "                    mul2=new2.mul(asym2)\n",
    "#                     import pdb;pdb.set_trace()\n",
    "\n",
    "                    p.add_(torch.mul(mul,d_p),alpha=-group['lr']).add_(torch.mul(mul2,d_p),alpha=-group['lr'])\n",
    "#                     import pdb;pdb.set_trace()\n",
    "                   \n",
    "                    counter+=1      \n",
    "                elif counter in [12,15,18,21,26,27]:\n",
    "#                     import pdb;pdb.set_trace()\n",
    "\n",
    "                    counter+=1\n",
    "                else:\n",
    "#                     import pdb;pdb.set_trace()\n",
    "\n",
    "                    p.add_(d_p, alpha=-group['lr'])\n",
    "#                     import pdb;pdb.set_trace()\n",
    "\n",
    "                    counter+=1\n",
    "                    continue\n",
    "        return loss \n",
    "    \n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def update(self, closure=None, count=[0]):\n",
    "        \"\"\"Performs a second optimization step\n",
    "        alpha here signifies lambda value in Tiki-Taka\"\"\"\n",
    "        \n",
    "        loss =None\n",
    "        if closure is not None:\n",
    "            with torch.enable_grad():\n",
    "                loss = closure()\n",
    "        \n",
    "        for group in self.param_groups:\n",
    "            weight_decay = group['weight_decay']\n",
    "            momentum = group['momentum']\n",
    "            dampening = group['dampening']\n",
    "            nesterov = group['nesterov']\n",
    "\n",
    "\n",
    "            if self.update_count<27:\n",
    "                group['params'][0]=group['params'][0].view(group['params'][0].size()[0],-1)\n",
    "                group['params'][12]=group['params'][12].view(group['params'][12].size()[0],-1)\n",
    "\n",
    "                asym=group['params'][12][:,self.update_count]*1.66+1\n",
    "                asym2=1-1.66*group['params'][12][:,self.update_count]\n",
    "                new=F.relu(torch.sign(group['params'][0][:,self.update_count]), inplace=False)\n",
    "\n",
    "                new2=F.relu(-torch.sign(group['params'][0][:,self.update_count]), inplace=False)\n",
    "                mul = new.mul(asym)\n",
    "                mul2=new2.mul(asym2)\n",
    "\n",
    "                group['params'][12][:,self.update_count].add_(torch.mul(mul,group['params'][0][:,self.update_count]), alpha=-0.02).add_(torch.mul(mul2,group['params'][0][:,self.update_count]), alpha=-0.02)\n",
    "#                 nn.init.zeros_(group['params'][0][:,self.update_count])\n",
    "                group['params'][0]=group['params'][0].view(group['params'][0].size()[0],3,3,3)\n",
    "                group['params'][12]=group['params'][12].view(group['params'][12].size()[0],3,3,3)\n",
    "                self.update_count+=1\n",
    "            \n",
    "\n",
    "            elif self.update_count>=27 and self.update_count<603:\n",
    "                group['params'][3]=group['params'][3].view(group['params'][3].size()[0],-1)\n",
    "                group['params'][15]=group['params'][15].view(group['params'][15].size()[0],-1)\n",
    "\n",
    "                asym=1+1.66*group['params'][15][:,self.update_count-27]\n",
    "                asym2=1-1.66*group['params'][15][:,self.update_count-27]\n",
    "                new=F.relu(torch.sign(group['params'][3][:,self.update_count-27]), inplace=False)\n",
    "                new2=F.relu(-torch.sign(group['params'][3][:,self.update_count-27]), inplace=False)\n",
    "                mul = new.mul(asym)\n",
    "                mul2=new2.mul(asym2)\n",
    "\n",
    "                group['params'][15][:,self.update_count-27].add_(torch.mul(mul,group['params'][3][:,self.update_count-27]), alpha=-0.02).add_(torch.mul(mul2,group['params'][3][:,self.update_count-27]), alpha=-0.02)\n",
    "#                 nn.init.zeros_(group['params'][4][:,self.update_count-27])\n",
    "                group['params'][3]=group['params'][3].view(group['params'][3].size()[0],64,3,3)\n",
    "                group['params'][15]=group['params'][15].view(group['params'][15].size()[0],64,3,3)\n",
    "\n",
    "                self.update_count+=1\n",
    "\n",
    "            elif self.update_count>=603 and self.update_count<1179:\n",
    "                group['params'][6]=group['params'][6].view(group['params'][6].size()[0],-1)\n",
    "                group['params'][18]=group['params'][18].view(group['params'][18].size()[0],-1)\n",
    "\n",
    "                asym=1+1.66*group['params'][18][:,self.update_count-603]\n",
    "                asym2=1-1.66*group['params'][18][:,self.update_count-603]\n",
    "                new=F.relu(torch.sign(group['params'][6][:,self.update_count-603]), inplace=False)\n",
    "                new2=F.relu(-torch.sign(group['params'][6][:,self.update_count-603]), inplace=False)\n",
    "                mul = new.mul(asym)\n",
    "                mul2=new2.mul(asym2)\n",
    "\n",
    "                group['params'][18][:,self.update_count-603].add_(torch.mul(mul,group['params'][6][:,self.update_count-603]), alpha=-0.02).add_(torch.mul(mul2,group['params'][6][:,self.update_count-603]), alpha=-0.02)\n",
    "#                 nn.init.zeros_(group['params'][8][:,self.update_count-603])\n",
    "                group['params'][6]=group['params'][6].view(group['params'][6].size()[0],64,3,3)\n",
    "                group['params'][18]=group['params'][18].view(group['params'][18].size()[0],64,3,3)\n",
    "\n",
    "                self.update_count+=1\n",
    "    \n",
    "            elif self.update_count>=1179 and self.update_count<2331:\n",
    "                group['params'][9]=group['params'][9].view(group['params'][9].size()[0],-1)\n",
    "                group['params'][21]=group['params'][21].view(group['params'][21].size()[0],-1)\n",
    "\n",
    "                asym=1+1.66*group['params'][21][:,self.update_count-1179]\n",
    "                asym2=1-1.66*group['params'][21][:,self.update_count-1179]\n",
    "                new=F.relu(torch.sign(group['params'][9][:,self.update_count-1179]), inplace=False)\n",
    "                new2=F.relu(-torch.sign(group['params'][9][:,self.update_count-1179]), inplace=False)\n",
    "                mul = new.mul(asym)\n",
    "                mul2=new2.mul(asym2)\n",
    "\n",
    "                group['params'][21][:,self.update_count-1179].add_(torch.mul(mul,group['params'][9][:,self.update_count-1179]), alpha=-0.02).add_(torch.mul(mul2,group['params'][9][:,self.update_count-1179]), alpha=-0.02)\n",
    "#                 nn.init.zeros_(group['params'][8][:,self.update_count-603])\n",
    "                group['params'][9]=group['params'][9].view(group['params'][9].size()[0],128,3,3)\n",
    "                group['params'][21]=group['params'][21].view(group['params'][21].size()[0],128,3,3)\n",
    "\n",
    "                self.update_count+=1\n",
    "    \n",
    "            elif self.update_count>=2331 and self.update_count<2341:\n",
    "                asym=1+1.66*group['params'][26][self.update_count-2331]\n",
    "                asym2=1-1.66*group['params'][26][self.update_count-2331]\n",
    "                new=F.relu(torch.sign(group['params'][24][self.update_count-2331]), inplace=False)\n",
    "                new2=F.relu(-torch.sign(group['params'][24][self.update_count-2331]), inplace=False)\n",
    "                mul = new.mul(asym)\n",
    "                mul2=new2.mul(asym2)\n",
    "\n",
    "                group['params'][26][self.update_count-2331].add_(torch.mul(mul,group['params'][24][self.update_count-2331]), alpha=-0.02).add_(torch.mul(mul2,group['params'][24][self.update_count-2331]), alpha=-0.02)\n",
    "#                 nn.init.zeros_(group['params'][8][:,self.update_count-603])\n",
    "                self.update_count+=1\n",
    "            \n",
    "            elif self.update_count==2341:\n",
    "                asym=1+1.66*group['params'][27]\n",
    "                asym2=1-1.66*group['params'][27]\n",
    "                new=F.relu(torch.sign(group['params'][25]), inplace=False)\n",
    "                new2=F.relu(-torch.sign(group['params'][25]), inplace=False)\n",
    "                mul = new.mul(asym)\n",
    "                mul2=new2.mul(asym2)\n",
    "\n",
    "                group['params'][27].add_(torch.mul(mul,group['params'][25]), alpha=-0.02).add_(torch.mul(mul2,group['params'][25]), alpha=-0.02)\n",
    "#                 nn.init.zeros_(group['params'][9])               \n",
    "                self.update_count=0\n",
    "            else:\n",
    "                assert False, \"Don't go here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Loss function and Optimizer'''\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.01\n",
    "optimizer = Tiki_Taka(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, batch_size, patience, n_epochs):\n",
    "    model.to(device)\n",
    "    # to track the training loss as the model trains\n",
    "    train_losses = []\n",
    "    train_accuracies=[]\n",
    "    # to track the validation loss as the model trains\n",
    "    valid_losses = []\n",
    "    valid_accuracies=[]\n",
    "    # to track the average training loss per epoch as the model trains\n",
    "    avg_train_losses = []\n",
    "    avg_train_accuracies=[]\n",
    "    # to track the average validation loss per epoch as the model trains\n",
    "    avg_valid_losses = []\n",
    "    avg_valid_accuracies=[]\n",
    "    \n",
    "    # initialize the early_stopping object\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "    scheduler = lr_sch.MultiStepLR(optimizer, milestones=[1,4,5,7,8,10],gamma=0.8)\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        ns=0\n",
    "        correct=0\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train() # prep model for training\n",
    "        for batch, data in enumerate(train_loader, 1):\n",
    "            inputs,target = data[0].to(device), data[1].to(device)\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(inputs)\n",
    "            # calculate the loss\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            if ns%30==29:\n",
    "#         if ns>0:\n",
    "                optimizer.update()\n",
    "            # record training loss\n",
    "            train_losses.append(loss.item())\n",
    "#             print(train_losses)\n",
    "#             print(type(train_losses))\n",
    "            pred=output.data.max(1,keepdim=True)[1]\n",
    "            correct=sum(pred.eq(target.data.view_as(pred)))*100./batch_size\n",
    "            train_accuracies.append(correct.item())\n",
    "#             print(correct)\n",
    "#             print(correct.item())\n",
    "            ns+=1\n",
    "            \n",
    "            if batch%1000==0:\n",
    "                train_loss=sum(train_losses[batch-1000:batch])/1000.\n",
    "                train_acc=sum(train_accuracies[batch-1000:batch])/1000.\n",
    "                print_inter=(f'epoch:{epoch}/{n_epochs} ' +\n",
    "                      f'step:{batch}/{len(train_loader)} ' +\n",
    "                      f'loss:{train_loss:.4f} '\n",
    "                      f'accuracy:{train_acc:.4f}'\n",
    "                     )\n",
    "                print(print_inter)\n",
    "            \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval() # prep model for evaluation\n",
    "        with torch.no_grad():    \n",
    "            for data in valid_loader:\n",
    "                inputs,target = data[0].to(device), data[1].to(device)\n",
    "                # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                output = model(inputs)\n",
    "                # calculate the loss\n",
    "                loss = criterion(output, target)\n",
    "                # record validation loss\n",
    "                valid_losses.append(loss.item())\n",
    "                pred=output.data.max(1,keepdim=True)[1]\n",
    "                correct=sum(pred.eq(target.data.view_as(pred)))*100./valid_batch_size\n",
    "                valid_accuracies.append(correct.item())\n",
    "#             import pdb;pdb.set_trace()\n",
    "        print(f\"lr:{optimizer.param_groups[0]['lr']}\")\n",
    "        \n",
    "        scheduler.step()\n",
    "        # print training/validation statistics \n",
    "        # calculate average loss over an epoch\n",
    "        train_loss = np.average(train_losses)\n",
    "        train_accuracy=np.average(train_accuracies)\n",
    "        valid_loss = np.average(valid_losses)\n",
    "        valid_accuracy=np.average(valid_accuracies)\n",
    "        avg_train_losses.append(train_loss)\n",
    "        avg_valid_losses.append(valid_loss)\n",
    "        avg_train_accuracies.append(train_accuracy)\n",
    "        avg_valid_accuracies.append(valid_accuracy)\n",
    "        \n",
    "        epoch_len = len(str(n_epochs))\n",
    "        \n",
    "        print_msg = (f'[{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +\n",
    "                     f'train_loss: {train_loss:.5f} ' +\n",
    "                     f'valid_loss: {valid_loss:.5f}'+\n",
    "                    f'train_accuracy:{train_accuracy:.5f}'+\n",
    "                    f'valid_accuracy:{valid_accuracy:.5f}')\n",
    "        \n",
    "        print(print_msg)\n",
    "#         import pdb;pdb.set_trace()\n",
    "\n",
    "        # clear lists to track next epoch\n",
    "        train_losses = []\n",
    "        train_accuracies=[]\n",
    "        valid_losses = []\n",
    "        valid_accuracies=[]\n",
    "        \n",
    "        # early_stopping needs the validation loss to check if it has decresed, \n",
    "        # and if it has, it will make a checkpoint of the current model\n",
    "        early_stopping(valid_accuracy, model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "#         torch.cuda.empty_cache()\n",
    "    # load the last checkpoint with the best model\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n",
    "    return  model, avg_train_losses, avg_valid_losses, avg_train_accuracies, avg_valid_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:0.01\n",
      "[ 1/30] train_loss: 1.19153 valid_loss: 1.00916train_accuracy:57.86889valid_accuracy:65.14000\n",
      "Validation loss decreased (inf --> 65.140005).  Saving model ...\n",
      "lr:0.008\n",
      "[ 2/30] train_loss: 0.78538 valid_loss: 0.86586train_accuracy:72.78889valid_accuracy:70.76000\n",
      "Validation loss decreased (65.140005 --> 70.760004).  Saving model ...\n",
      "lr:0.008\n",
      "[ 3/30] train_loss: 0.60800 valid_loss: 0.84765train_accuracy:79.47556valid_accuracy:71.86000\n",
      "Validation loss decreased (70.760004 --> 71.860002).  Saving model ...\n",
      "lr:0.008\n",
      "[ 4/30] train_loss: 0.48372 valid_loss: 0.84965train_accuracy:83.86667valid_accuracy:72.30000\n",
      "Validation loss decreased (71.860002 --> 72.300003).  Saving model ...\n",
      "lr:0.0064\n",
      "[ 5/30] train_loss: 0.35956 valid_loss: 0.85603train_accuracy:88.95333valid_accuracy:72.68000\n",
      "Validation loss decreased (72.300003 --> 72.680003).  Saving model ...\n",
      "lr:0.00512\n",
      "[ 6/30] train_loss: 0.26527 valid_loss: 0.85551train_accuracy:92.95778valid_accuracy:72.72000\n",
      "Validation loss decreased (72.680003 --> 72.720004).  Saving model ...\n",
      "lr:0.00512\n",
      "[ 7/30] train_loss: 0.21113 valid_loss: 0.88321train_accuracy:94.88667valid_accuracy:72.06000\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr:0.004096000000000001\n",
      "[ 8/30] train_loss: 0.15572 valid_loss: 0.88060train_accuracy:97.14000valid_accuracy:73.30000\n",
      "Validation loss decreased (72.720004 --> 73.300002).  Saving model ...\n",
      "lr:0.0032768000000000007\n",
      "[ 9/30] train_loss: 0.12173 valid_loss: 0.89942train_accuracy:98.36667valid_accuracy:72.96000\n",
      "EarlyStopping counter: 1 out of 10\n",
      "lr:0.0032768000000000007\n",
      "[10/30] train_loss: 0.10245 valid_loss: 0.90972train_accuracy:98.87333valid_accuracy:72.56000\n",
      "EarlyStopping counter: 2 out of 10\n",
      "lr:0.002621440000000001\n",
      "[11/30] train_loss: 0.08470 valid_loss: 0.92536train_accuracy:99.30889valid_accuracy:72.92000\n",
      "EarlyStopping counter: 3 out of 10\n",
      "lr:0.002621440000000001\n",
      "[12/30] train_loss: 0.07521 valid_loss: 0.93292train_accuracy:99.48222valid_accuracy:72.84000\n",
      "EarlyStopping counter: 4 out of 10\n",
      "lr:0.002621440000000001\n",
      "[13/30] train_loss: 0.06718 valid_loss: 0.94067train_accuracy:99.61778valid_accuracy:72.74000\n",
      "EarlyStopping counter: 5 out of 10\n",
      "lr:0.002621440000000001\n",
      "[14/30] train_loss: 0.05937 valid_loss: 0.94661train_accuracy:99.76000valid_accuracy:72.80000\n",
      "EarlyStopping counter: 6 out of 10\n",
      "lr:0.002621440000000001\n",
      "[15/30] train_loss: 0.05386 valid_loss: 0.95540train_accuracy:99.80222valid_accuracy:72.94000\n",
      "EarlyStopping counter: 7 out of 10\n",
      "lr:0.002621440000000001\n",
      "[16/30] train_loss: 0.04852 valid_loss: 0.97189train_accuracy:99.87556valid_accuracy:72.98000\n",
      "EarlyStopping counter: 8 out of 10\n",
      "lr:0.002621440000000001\n",
      "[17/30] train_loss: 0.04413 valid_loss: 0.97804train_accuracy:99.89778valid_accuracy:72.96000\n",
      "EarlyStopping counter: 9 out of 10\n",
      "lr:0.002621440000000001\n",
      "[18/30] train_loss: 0.03969 valid_loss: 0.98797train_accuracy:99.92222valid_accuracy:72.92000\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "# model.to(device)\n",
    "\n",
    "n_epochs = 30\n",
    "\n",
    "train_loader, test_loader, valid_loader \n",
    "\n",
    "# early stopping patience; how long to wait after last time validation loss improved.\n",
    "patience = 10\n",
    "\n",
    "model, train_loss, valid_loss, train_accuracy, valid_accuracy = train_model(model, batch_size, patience, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = \"cifar10.pt\"\n",
    "# torch.save(model.state_dict(),PATH)\n",
    "# torch.save(model.module.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0091642141342163, 0.8658557772636414, 0.8476454496383667, 0.8496529340744019, 0.856030011177063, 0.8555091023445129, 0.8832132458686829, 0.8806047916412354, 0.8994194269180298, 0.9097179889678955, 0.9253580331802368, 0.9329177141189575, 0.9406670451164245, 0.9466103434562683, 0.9553968787193299, 0.9718927383422852, 0.9780387163162232, 0.9879682898521424]\n",
      "[1.1915303795867496, 0.7853760276900398, 0.6080008646514681, 0.48372155911392634, 0.3595615454514821, 0.26527412318521076, 0.21112751020325554, 0.1557205060786671, 0.12173194181587961, 0.10245436447362105, 0.08470242943200801, 0.07521438445481989, 0.06718261374367608, 0.05936969099773301, 0.05386348187095589, 0.04852256681356165, 0.0441347652218408, 0.039685885993142926]\n"
     ]
    }
   ],
   "source": [
    "print(valid_loss)\n",
    "print(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the loss as the network trained\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n",
    "plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')\n",
    "\n",
    "# find position of lowest validation loss\n",
    "minposs = valid_loss.index(min(valid_loss))+1 \n",
    "plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
    "\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.ylim(0, 1.0) # consistent scale\n",
    "plt.xlim(0, len(train_loss)+1) # consistent scale\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('loss_plot.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the loss as the network trained\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(range(1,len(train_accuracy)+1),train_accuracy, label='Training Accuracy')\n",
    "plt.plot(range(1,len(valid_accuracy)+1),valid_accuracy,label='Validation Accuracy')\n",
    "\n",
    "# find position of lowest validation loss\n",
    "maxposs = valid_accuracy.index(max(valid_accuracy))+1 \n",
    "plt.axvline(maxposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
    "\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "# plt.ylim(0, 0.5) # consistent scale\n",
    "# plt.xlim(0, len(train_loss)+1) # consistent scale\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('accuracy_plot.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.403628\n",
      "\n",
      "Test Accuracy of plane: 58% (588/1000)\n",
      "Test Accuracy of   car: 72% (724/1000)\n",
      "Test Accuracy of  bird: 24% (243/1000)\n",
      "Test Accuracy of   cat: 40% (400/1000)\n",
      "Test Accuracy of  deer: 49% (491/1000)\n",
      "Test Accuracy of   dog: 45% (454/1000)\n",
      "Test Accuracy of  frog: 43% (431/1000)\n",
      "Test Accuracy of horse: 57% (578/1000)\n",
      "Test Accuracy of  ship: 65% (656/1000)\n",
      "Test Accuracy of truck: 54% (546/1000)\n",
      "\n",
      "Test Accuracy (Overall): 51% (5111/10000)\n"
     ]
    }
   ],
   "source": [
    "# initialize lists to monitor test loss and accuracy\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "# device=torch.device(\"cuda\")\n",
    "# model.load_state_dict(torch.load(PATH, map_location=\"cuda:0\"))\n",
    "model.to(device)\n",
    "model.eval() # prep model for evaluation\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs,target = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        if len(target.data) != test_batch_size:\n",
    "            break\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(inputs)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update test loss \n",
    "        test_loss += loss.item()*inputs.size(0)\n",
    "        # convert output probabilities to predicted class\n",
    "        _, pred = torch.max(output, 1)\n",
    "        # compare predictions to true label\n",
    "        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "        # calculate test accuracy for each object class\n",
    "        for i in range(test_batch_size):\n",
    "            label = target.data[i]\n",
    "            class_correct[label] += correct[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "# calculate and print avg test loss\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "# labels = [\"plane\",\"car\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            str(classes[i]), 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "#     else:\n",
    "#         print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
